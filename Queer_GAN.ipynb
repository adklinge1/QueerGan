{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "anaconda-cloud": {},
    "colab": {
      "name": "Queer_GAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.9 (tensorflow)",
      "language": "python",
      "name": "tensorflow"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adklinge1/QueerGan/blob/main/Queer_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2fejML3tCfv"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_07_3_style_gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umnLFIB3-ZS9"
      },
      "source": [
        "## This Queer Does Not Exists \n",
        "\n",
        "AI reflects the perspectives of those who design them - with  hetronormative, binary conceptions of gender. According to a [research](https://www.colorado.edu/today/2019/10/08/facial-recognition-software-has-gender-problem) by the University of Colorado Boulder, the most popular facial recognition technologies in the market are guilty of inaccurately classifying the gender of trans and non-gender-conforming individuals. Nonetheless, industries and governments around the world quickly adopt cis-sexist AI applications (such as Gender detection algorithms), and thus perpetuate the system of oppression and relegates those who do not fit into gender binaries to a subclass of human existence.\n",
        "\n",
        "StyleGan2, like Gender Detection AI, also preserves the bias by generating only images of heteronormative women and men. This bias is likely inherited from the dataset StyleGan was trained on.\n",
        "___\n",
        "\n",
        "\n",
        "\n",
        "This project is a radical version of the [NVidia StyleGAN2 ADA](https://github.com/NVlabs/stylegan2-ada) project, which aims to generate **only Queer people**.  \n",
        " \n",
        "[\"Queer\"](https://en.wikipedia.org/wiki/Queer) is an umbrella term for gender minorities who are not [heterosexual](https://en.wikipedia.org/wiki/Heterosexuality) or are not [cisgender](https://en.wikipedia.org/wiki/Cisgender). \n",
        "\n",
        "\n",
        "\n",
        "\n",
        " ___\n",
        "\n",
        "In this project we used different tools :\n",
        "* NVidia StyleGAN2 ADA](https://github.com/NVlabs/stylegan2-ada) model\n",
        "* \n",
        "\n",
        "Like Audre Lord, one of the most famous femenist activists, claimed : \"“The master's tools will never dismantle the master's house” \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pWkgt0INbRK"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2dEcHb9tCf6",
        "outputId": "a510b164-9975-42cb-c126-13261f2c8b63"
      },
      "source": [
        "# Mount G-Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icRPLmPKtCf_"
      },
      "source": [
        "Next, clone StyleGAN2 ADA PyTorch and Gender-And-Age-Detection from GitHub."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kq7ii0gkVssV"
      },
      "source": [
        "!git clone https://github.com/NVlabs/stylegan2-ada-pytorch.git\n",
        "!pip install ninja\n",
        "\n",
        "# !git clone https://github.com/smahesh29/Gender-and-Age-Detection.git\n",
        "!pip install opencv-python\n",
        "!pip install cvlib\n",
        "!pip install argparse\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQGFXRI0tCgG"
      },
      "source": [
        "## Run StyleGan2 From Command Line\n",
        "The code below is based on code from NVidia. This actually generates your images. When you use StyleGAN you will generally create a GAN from a seed number, such as 6600.  GANs are actually created by a latent vector, containing 512 floating point values.  The seed is used by the GAN code to generate these 512 values.  The seed value is easier to represent in code than a 512 value vector.  However, while a small change to the latent vector results in a small change to the image, even a small change to the seed value will produce a radically different image.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wn_lpC_p-4ag",
        "outputId": "8f766230-5159-45d4-d0fa-d2695e25ee2e"
      },
      "source": [
        "!python /content/stylegan2-ada-pytorch/generate.py \\\n",
        "    --network=https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/ffhq.pkl \\\n",
        "  --outdir=/content/results --seeds=8193"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading networks from \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/ffhq.pkl\"...\n",
            "Downloading https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/ffhq.pkl ... done\n",
            "Generating image for seed 8193 (0/1) ...\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeUdlQkINRI5"
      },
      "source": [
        "Next, copy the images to a folder of your choice on GDrive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D92Md-Hw3eVA"
      },
      "source": [
        "## Run StyleGAN2 From Python Code\n",
        "\n",
        "Add the StyleGAN2 folder to Python so that you can import it.  The code below is based on code from NVIDIA. This actually generates your images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgMm1sSutCgH"
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0, \"/content/stylegan2-ada-pytorch\")\n",
        "import pickle\n",
        "import os\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display\n",
        "import torch\n",
        "import dnnlib\n",
        "import legacy\n",
        "\n",
        "def seed2vec(G, seed):\n",
        "  return np.random.RandomState(seed).randn(1, G.z_dim)\n",
        "\n",
        "def display_image(image):\n",
        "  plt.axis('off')\n",
        "  plt.imshow(image)\n",
        "  plt.show()\n",
        "\n",
        "def generate_image(G, z, truncation_psi):\n",
        "    # Render images for dlatents initialized from random seeds.\n",
        "    Gs_kwargs = {\n",
        "        'output_transform': dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True),\n",
        "        'randomize_noise': False\n",
        "    }\n",
        "    if truncation_psi is not None:\n",
        "        Gs_kwargs['truncation_psi'] = truncation_psi\n",
        "\n",
        "    label = np.zeros([1] + G.input_shapes[1][1:])\n",
        "    images = G.run(z, label, **G_kwargs) # [minibatch, height, width, channel]\n",
        "    return images[0]\n",
        "\n",
        "def get_label(G, device, class_idx):\n",
        "  label = torch.zeros([1, G.c_dim], device=device)\n",
        "  if G.c_dim != 0:\n",
        "      if class_idx is None:\n",
        "          ctx.fail('Must specify class label with --class when using a conditional network')\n",
        "      label[:, class_idx] = 1\n",
        "  else:\n",
        "      if class_idx is not None:\n",
        "          print ('warn: --class=lbl ignored when running on an unconditional network')\n",
        "  return label\n",
        "\n",
        "def generate_image(device, G, z, truncation_psi=1.0, noise_mode='const', class_idx=None):\n",
        "  z = torch.from_numpy(z).to(device)\n",
        "  label = get_label(G, device, class_idx)\n",
        "  img = G(z, label, truncation_psi=truncation_psi, noise_mode=noise_mode)\n",
        "  img = (img.permute(0, 2, 3, 1) * 127.5 + 128).clamp(0, 255).to(torch.uint8)\n",
        "  return PIL.Image.fromarray(img[0].cpu().numpy(), 'RGB')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gztmiDKIOE9u"
      },
      "source": [
        "Load the model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjBnVUXtRhqN",
        "outputId": "d35422b8-20e0-404a-a7e9-31001474f9d3"
      },
      "source": [
        "URL = \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/ffhq.pkl\"\n",
        "\n",
        "print(f'Loading networks from \"{URL}\"...')\n",
        "device = torch.device('cuda')\n",
        "with dnnlib.util.open_url(URL) as f:\n",
        "    G = legacy.load_network_pkl(f)['G_ema'].to(device) # type: ignore"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading networks from \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/ffhq.pkl\"...\n",
            "Downloading https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/ffhq.pkl ... done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9qAQxguj-wV"
      },
      "source": [
        "import sys\n",
        "# sys.path.insert(0, \"/Gender-and-Age-Detection\")\n",
        "import cv2\n",
        "import cvlib as cv\n",
        "import sys\n",
        "import numpy as np\n",
        "from termcolor import colored\n",
        "\n",
        "def Generate_queer_img(G, seed, STEPS = 100, outputDir = 'queers'):\n",
        "  os.makedirs(f\"./results/{outputDir}\", exist_ok=True)\n",
        "\n",
        "  v1 = seed2vec(G, seed)\n",
        "  initial_seed_img_path = f'/content/results/seed-{seed}.png';\n",
        "  img = generate_image(device, G, v1)\n",
        "  img.save(initial_seed_img_path)\n",
        "\n",
        "  # detect gender\n",
        "  isWoman, confidence = Is_Woman(initial_seed_img_path)\n",
        "  print(colored(f'Seed {seed} was identified as {(\"woman\" if isWoman else \"man\")}. (Confidence : {confidence if isWoman else 100-confidence})', 'green'))\n",
        "  \n",
        "  # Generate partner of opposite sex\n",
        "  partnerSeed, pConfidence = Generate_Seed_By_Gender(G, False) if isWoman else Generate_Seed_By_Gender(G, True)\n",
        "  print(colored(f'partner seed {partnerSeed} was identified as {(\"man\" if isWoman else \"woman\")}. (Confidence : {pConfidence}', 'green'))\n",
        "\n",
        "  parnerVector = seed2vec(G, partnerSeed)\n",
        "  \n",
        "  # Breed to get the queer child \n",
        "  diff = parnerVector - v1;\n",
        "  stepSize = diff / STEPS\n",
        "\n",
        "  # Move in latent space towards the partner untill the gender is flipped\n",
        "  for i in range(1, STEPS):\n",
        "    child = v1 + (i * stepSize)\n",
        "    childPath = f'/content/results/temp/seed_{seed}+{i}_steps_to_seed_{partnerSeed}.png'\n",
        "    img = generate_image(device, G, child)\n",
        "    img.save(childPath)\n",
        "    childIsWoman, confidence = Is_Woman(childPath)\n",
        "    genderFlipped = childIsWoman != isWoman\n",
        "    if genderFlipped : \n",
        "      outdirPath = f'/content/results/{outputDir}/seed_{seed}+{i}_steps_to_seed_{partnerSeed}_{confidence}%_woman.png'\n",
        "      img.save(outdirPath)\n",
        "      print(colored(f'Queer child of seeds: {seed} + {partnerSeed} was saved in : {outdirPath}', 'blue'))\n",
        "\n",
        "      break;\n",
        "\n",
        "def Is_Woman(img_path, required_confidence = 50):\n",
        "  img = cv2.imread(img_path)\n",
        "  label, confidence = cv.detect_gender(img)\n",
        "  # print(colored(f'path : {img_path}. Confidence : {confidence[1]*100} % woman', 'yellow'))\n",
        "  return (confidence[1] * 100) > required_confidence, (confidence[1] * 100)\n",
        "\n",
        "def Generate_Seed_By_Gender(G, woman, TRIALS = 10):\n",
        "  for i in range(0, TRIALS):\n",
        "    randSeed = Get_Random_Seed()\n",
        "    v = seed2vec(G, randSeed)\n",
        "    img = generate_image(device, G,v)\n",
        "    randSeedPath = f'/content/results/Seed-{randSeed}.png'\n",
        "    img.save(randSeedPath)\n",
        "    isRandSeedWoman, confidence = Is_Woman(randSeedPath)\n",
        "\n",
        "    if(woman == isRandSeedWoman):\n",
        "\n",
        "      # print(colored(f'Seed {randSeed} was identified as a {(\"woman\" if isRandSeedWoman else \"man\")}' ,'green'))\n",
        "      return randSeed, (confidence if woman else 100 - confidence)\n",
        "    \n",
        "    # delete img\n",
        "    !rm '{randSeedPath}'\n",
        "\n",
        "def Get_Random_Seed(maxValue = 100000):\n",
        "  rng = np.random.default_rng()\n",
        "  rints = rng.integers(low=0, high=maxValue, size=1)\n",
        "  # print(f'Random seed : {rints[0]}')\n",
        "  return rints[0]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HslkdJVVOkKt"
      },
      "source": [
        "Run the bellow snippet to Generate the desired amount of Queer images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMzCgWC10bne"
      },
      "source": [
        "import shutil\n",
        "\n",
        "NumberOfQueerPhotos = 10;\n",
        "\n",
        "for i in range(0, NumberOfQueerPhotos):\n",
        "  randomSeed = Get_Random_Seed()\n",
        "\n",
        "  # clear temportal results of previous breeding processes\n",
        "  shutil.rmtree('./results/temp', ignore_errors=True)\n",
        "\n",
        "\n",
        "  os.makedirs(\"./results/temp\", exist_ok=True)\n",
        "  Generate_queer_img(G, randomSeed)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUBDBTkL2apG"
      },
      "source": [
        "---\n",
        "\n",
        "# Copy the Queers folder into you drive \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rh5faG6AOFA"
      },
      "source": [
        "cp /content/results/queers/* \\\n",
        "    /content/drive/MyDrive/QueerGan"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}